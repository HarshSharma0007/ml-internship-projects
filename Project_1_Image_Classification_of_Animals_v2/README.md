# ğŸ¾ Animal Image Classification â€“ Version 2

> A full-stack deep learning solution for multi-class animal image classification using ResNet18, Captum explainability, and beautiful interactive frontends in **Streamlit** and **Gradio**. Built for performance, transparency, and deployment-readiness. Built from scratch with modular design and a strong emphasis on performance, explainability, and ML engineering principles.

---

## ğŸŒŸ Project Highlights

- ğŸ§  **ResNet18 Transfer Learning** with fine-tuned final layers  
- ğŸ–¼ï¸ **15 Animal Classes** including ğŸ¯ Tiger, ğŸ¼ Panda, ğŸ¶ Dog, ğŸ˜ Elephant, and more  
- ğŸ“ˆ **93.15% Accuracy** on validation set  
- âœ¨ **Explainability** via **Captum** (Integrated Gradients + Saliency)  
- ğŸš€ **Dual Frontends**:
  - `Streamlit` for local dashboard presentation  
  - `Gradio` for fast hosted demo or colab-style interface  
- ğŸ“ **Modular Design**: train/test/infer pipelines decoupled and reusable  
- ğŸ“Š **Tracked Evaluation**: class-wise metrics, heatmaps, Top-3 probabilities  

---

## ğŸ”§ Key Features
- ğŸ“¦ **Transfer Learning** with ResNet and EfficientNet backbones  
- ğŸ”„ **Data Augmentation** using Albumentations  
- ğŸ§  **Ensemble Modeling** via soft voting  
- ğŸ” **Grad-CAM Explainability** for interpretability  
- ğŸ“Š **Stratified Splitting & Summary Reports** to audit data distribution  
- ğŸ§ª **MLflow** for experiment tracking

---

## ğŸ§± Tech Stack

| Type            | Tools / Libraries                        |
|------------------|-------------------------------------------|
| Language         | Python 3.10+                              |
| Frameworks       | PyTorch (ResNet18), TorchVision           |
| Explainability   | Captum (IG, Saliency), Matplotlib         |
| Image Handling   | Pillow, OpenCV, Albumentations            |
| UI / UX          | Streamlit, Gradio                         |
| Data Utils       | scikit-learn, Pandas, Pillow              |
| DevOps           | Git, Github                                       |
| Tracking         | MLflow, CSV summaries                     |
| Deployment       | Gradio share link or Streamlit local app  |

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Original dataset (class-wise folders)
â”‚   â”œâ”€â”€ processed/    # Train / Val / Test splits after stratification
â”‚   â”‚    â”œâ”€â”€ test/
â”‚   â”‚    â”œâ”€â”€ train/
â”‚   â”‚    â””â”€â”€ val/   
â”‚   â””â”€â”€ splits/       # CSVs tracking split assignments
â”‚
â”œâ”€â”€ models/           # Saved model weights (.pt)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_split_and_explore.ipynb       # Stratified split + distribution plots
â”‚   â”œâ”€â”€ 02_dataloader_test.ipynb
â”‚   â”œâ”€â”€ 03_train_in_notebook.ipynb
â”‚   â”œâ”€â”€ 04_evaluate_model.ipynb
â”‚   â”œâ”€â”€ 05_project_summary.ipynb
â”‚   â”œâ”€â”€ 06_two_models_evaluation.ipynb
â”‚   â””â”€â”€ 07_captum_explainability.ipynb
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€  explainability/                      # Captum Attribution images per class
â”‚   â”œâ”€â”€  Model1/                              # Model with high accuracy
â”‚        â”œâ”€â”€ metrics.txt
â”‚        â”œâ”€â”€ per_class_metrics.csv
â”‚        â””â”€â”€ class_distribution_summary.csv   # Count of images per class per split
â”‚   â”œâ”€â”€  metrics.txt
â”‚   â”œâ”€â”€  per_class_metrics.csv
â”‚   â””â”€â”€ class_distribution_summary.csv        # Count of images per class per split
â”‚    
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ interpret/
â”‚       â””â”€â”€ captum_visualizer.py
â”‚   â”œâ”€â”€ models/ 
â”‚       â”œâ”€â”€ effnet.py
â”‚       â””â”€â”€ resnet.py
â”‚   â”œâ”€â”€ utils/
â”‚       â””â”€â”€ helpers.py
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ dataloader.py
â”‚   â”œâ”€â”€ ensemble.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ train.py
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ assets/
â”‚       â””â”€â”€ sample_images/
â”‚   â”œâ”€â”€ models/ 
â”‚   â”œâ”€â”€ utils/
â”‚       â”œâ”€â”€ inference.py     # Prediction wrapper
â”‚       â””â”€â”€ captum_utils.py  # Attribution backend
â”‚   â”œâ”€â”€ Home.py              # Streamlit UI
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ gradio_app/
â”‚   â”œâ”€â”€ examples/
â”‚       â””â”€â”€ sample_images/
â”‚   â”œâ”€â”€ models/ 
â”‚   â”œâ”€â”€ utils/
â”‚       â””â”€â”€ infer_example.py     # Gradio backend interface
â”‚   â””â”€â”€ app.py                   # Gradio frontend launcher
â”‚   
â”œâ”€â”€ requirements.lock
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Model Details

- ğŸ“š Architecture: ResNet18 with final layer adapted to 15-class softmax  
- ğŸ‹ï¸â€â™‚ï¸ Training: 20 epochs with ImageNet-sized inputs (224Ã—224)  
- ğŸ“ˆ Achieved 93.15% validation accuracy  
- ğŸ§  Saved model: `models/resnet18_20250702_155546.pt`  
- ğŸ” Loss: CrossEntropyLoss | Optimizer: Adam | Scheduler: StepLR  
- ğŸ”„ Augmentations via **Albumentations** during training



## ğŸ§ª Captum-Based Explainability

- Implemented using `captum.attr` and custom renderer `plot_attributions`
- Attribution methods:
  - **Integrated Gradients** â€“ smooth, interpretable
  - **Saliency Maps** â€“ fast, gradient-based
- Works across both Streamlit and Gradio interfaces



## ğŸ“Š Streamlit Dashboard

Launch locally for a highly polished dashboard experience:

### â–¶ï¸ Start the app:

```bash
cd streamlit_app
streamlit run Home.py
```

### Features:
- File uploader + sample selector
- Prediction panel with emoji-tagged Top-3 classes
- Class-wise confidence bars
- Attribution heatmap side-by-side
- Integrated / Saliency toggle via sidebar
- Reset + minimal UX design



## ğŸŒ Gradio Interface

For quick sharing or integration with Hugging Face / notebooks / colab:

### â–¶ï¸ Start the app:

```bash
python app.py
```

### Features:
- Input: Upload or pick sample image
- Attribution method toggle (IG / Saliency)
- Outputs: Top-3 confidence map + Explanation heatmap
- Compatible with Hugging Face Spaces deployment




## ğŸ Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/HarshSharma0007/ml-internship-projects.git
cd Project_1_Image_Classification_of_Animals_v2
```

### 2. Create environment

```bash
python -m venv venv
venv\Scripts\activate      # Windows
source venv/bin/activate   # Linux/macOS
```

### 3. Install requirements

```bash
pip install -r requirements.txt
```

---